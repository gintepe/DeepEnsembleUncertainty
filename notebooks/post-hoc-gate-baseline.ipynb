{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit ('proj-env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "48b64db227b3f5cb4afbfc07e90e202d0142ea2a06daaa20f8a619f487d7f983"
   }
  },
  "interpreter": {
   "hash": "48b64db227b3f5cb4afbfc07e90e202d0142ea2a06daaa20f8a619f487d7f983"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import datasets.mnist as mnist\n",
    "import datasets.cifar10 as cifar10\n",
    "import constants\n",
    "from configuration import Configuration, DEFAULT_DICT\n",
    "from methods.moe.MixtureOfExperts import SimpleMoE\n",
    "from methods.mcdropout.MCDropout import MCDropout\n",
    "from methods.BaseTrainer import StatisticsTracker\n",
    "from util import *\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train a MoE model using a class-based allocation to experts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "args = Configuration(DEFAULT_DICT)\n",
    "args.moe_gating = 'simple'\n",
    "args.method = 'moe'\n",
    "args.n = 5\n",
    "args.model = 'lenet'\n",
    "args.optimizer = 'adam'\n",
    "# args.cpu = True\n",
    "args.moe_type = 'fixed'\n",
    "args.predict_gated = True\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "t = get_trainer(args, 'cuda')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using a simple gate\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "t.model.gate_by_class = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_loader, valid_loader = mnist.get_mnist_train_valid_loader(args.data_dir, args.batch_size, random_seed=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# train for the same number of epochs as a regular MoE model would\n",
    "# reported validation results can be ignored as the gating network output is used there, not class-allocations \n",
    "t.fit(train_loader, valid_loader, epochs=5, log=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.003\n",
      "    weight_decay: 0\n",
      ")\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Epoch 1\n",
      "100%|██████████| 216/216 [00:06<00:00, 32.99batch/s, loss=0.0418]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 1: [   0. 6046.    0.    0.    0.]\n",
      "Loads for the epoch label 2: [   0.    0. 5356.    0.    0.]\n",
      "Loads for the epoch label 3: [   0.    0.    0. 5495.    0.]\n",
      "Loads for the epoch label 4: [   0.    0.    0.    0. 5267.]\n",
      "Loads for the epoch label 5: [4875.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 6: [   0. 5291.    0.    0.    0.]\n",
      "Loads for the epoch label 7: [   0.    0. 5641.    0.    0.]\n",
      "Loads for the epoch label 8: [   0.    0.    0. 5275.    0.]\n",
      "Loads for the epoch label 9: [   0.    0.    0.    0. 5388.]\n",
      "Loads for the epoch: [10241. 11337. 10997. 10770. 10655.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 41.08batch/s, loss=3.46]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 3.2067925532658896; accuracy: 0.201\n",
      "\n",
      "Epoch 2\n",
      "100%|██████████| 216/216 [00:06<00:00, 31.53batch/s, loss=0.0235]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 1: [   0. 6046.    0.    0.    0.]\n",
      "Loads for the epoch label 2: [   0.    0. 5356.    0.    0.]\n",
      "Loads for the epoch label 3: [   0.    0.    0. 5495.    0.]\n",
      "Loads for the epoch label 4: [   0.    0.    0.    0. 5267.]\n",
      "Loads for the epoch label 5: [4875.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 6: [   0. 5291.    0.    0.    0.]\n",
      "Loads for the epoch label 7: [   0.    0. 5641.    0.    0.]\n",
      "Loads for the epoch label 8: [   0.    0.    0. 5275.    0.]\n",
      "Loads for the epoch label 9: [   0.    0.    0.    0. 5388.]\n",
      "Loads for the epoch: [10241. 11337. 10997. 10770. 10655.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 41.25batch/s, loss=3.07]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 3.2039759953816733; accuracy: 0.20016666666666666\n",
      "\n",
      "Epoch 3\n",
      "100%|██████████| 216/216 [00:06<00:00, 32.44batch/s, loss=0.0149]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 1: [   0. 6046.    0.    0.    0.]\n",
      "Loads for the epoch label 2: [   0.    0. 5356.    0.    0.]\n",
      "Loads for the epoch label 3: [   0.    0.    0. 5495.    0.]\n",
      "Loads for the epoch label 4: [   0.    0.    0.    0. 5267.]\n",
      "Loads for the epoch label 5: [4875.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 6: [   0. 5291.    0.    0.    0.]\n",
      "Loads for the epoch label 7: [   0.    0. 5641.    0.    0.]\n",
      "Loads for the epoch label 8: [   0.    0.    0. 5275.    0.]\n",
      "Loads for the epoch label 9: [   0.    0.    0.    0. 5388.]\n",
      "Loads for the epoch: [10241. 11337. 10997. 10770. 10655.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 41.14batch/s, loss=3.31]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 3.204744537671407; accuracy: 0.199\n",
      "\n",
      "Epoch 4\n",
      "100%|██████████| 216/216 [00:06<00:00, 32.78batch/s, loss=0.0057]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 1: [   0. 6046.    0.    0.    0.]\n",
      "Loads for the epoch label 2: [   0.    0. 5356.    0.    0.]\n",
      "Loads for the epoch label 3: [   0.    0.    0. 5495.    0.]\n",
      "Loads for the epoch label 4: [   0.    0.    0.    0. 5267.]\n",
      "Loads for the epoch label 5: [4875.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 6: [   0. 5291.    0.    0.    0.]\n",
      "Loads for the epoch label 7: [   0.    0. 5641.    0.    0.]\n",
      "Loads for the epoch label 8: [   0.    0.    0. 5275.    0.]\n",
      "Loads for the epoch label 9: [   0.    0.    0.    0. 5388.]\n",
      "Loads for the epoch: [10241. 11337. 10997. 10770. 10655.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 39.46batch/s, loss=3.18]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 3.1976287364959717; accuracy: 0.20066666666666666\n",
      "\n",
      "Epoch 5\n",
      "100%|██████████| 216/216 [00:06<00:00, 34.51batch/s, loss=0.0293]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 1: [   0. 6046.    0.    0.    0.]\n",
      "Loads for the epoch label 2: [   0.    0. 5356.    0.    0.]\n",
      "Loads for the epoch label 3: [   0.    0.    0. 5495.    0.]\n",
      "Loads for the epoch label 4: [   0.    0.    0.    0. 5267.]\n",
      "Loads for the epoch label 5: [4875.    0.    0.    0.    0.]\n",
      "Loads for the epoch label 6: [   0. 5291.    0.    0.    0.]\n",
      "Loads for the epoch label 7: [   0.    0. 5641.    0.    0.]\n",
      "Loads for the epoch label 8: [   0.    0.    0. 5275.    0.]\n",
      "Loads for the epoch label 9: [   0.    0.    0.    0. 5388.]\n",
      "Loads for the epoch: [10241. 11337. 10997. 10770. 10655.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 26.49batch/s, loss=3.13]Validation loss: 3.198423763116201; accuracy: 0.19766666666666666\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test using the same class-based gating"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_loader = mnist.get_test_loader(args.data_dir, args.batch_size, corrupted=False)#, intensity=i, corruption='rotation')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "metric_dict = {'NLL': lambda p, g: metrics.basic_cross_entropy(p, g).item(), \n",
    "                    'ECE': metrics.wrap_ece(bins=20), \n",
    "                    'Brier': metrics.wrap_brier()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "t.model.eval()\n",
    "\n",
    "stat_tracker = StatisticsTracker(args.n)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "        metric_accumulators = defaultdict(int)\n",
    "        for X, y in tepoch:\n",
    "\n",
    "            X, y = X.to(t.device), y.to(t.device)\n",
    "            \n",
    "            y_hat, preds, batch_loads, batch_loads_by_label, load_loss = t.model(X, labels=y)\n",
    "\n",
    "            for name, metric in metric_dict.items():\n",
    "                metric_val = metric(y_hat, y)\n",
    "                # assumes all metrics are mean-reduced\n",
    "                metric_accumulators[name] += metric_val * X.size(0)\n",
    "\n",
    "            stat_tracker.update(y_hat, preds, y)\n",
    "\n",
    "    correct = stat_tracker.correct\n",
    "    total = stat_tracker.total\n",
    "\n",
    "    test_accuracy = correct/total\n",
    "    print(f'Results: \\nAccuracy: {test_accuracy}')\n",
    "    for name, val in metric_accumulators.items():\n",
    "        metric_accumulators[name] = val/total\n",
    "        print(f'{name}: {metric_accumulators[name]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?batch/s]/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 40/40 [00:00<00:00, 40.67batch/s]Results: \n",
      "Accuracy: 0.996\n",
      "NLL: 0.01472758359159343\n",
      "ECE: 0.005053635632991796\n",
      "Brier: 0.006774707189106266\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It does not appear that the networks overfitting as part of a MoE model would have a negative effect on their performance in terms of accuracy - we have shown above that when using the \"oracle\" expert - the one that has been trained on the class of a given sample - we can obtain a near perfect classification accuracy. There could, however, be an issue in the gating network and its level of over- or under-fitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train a post-hoc gating network via the ensemble loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from methods.moe.gate_models import SimpleConvGate, GateWrapper"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "t.model.gate_by_class = False\n",
    "t.gated_predict = True\n",
    "t.model.train();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "\n",
    "sg = GateWrapper(SimpleConvGate(28, 5))\n",
    "sg.to(t.device)\n",
    "t.model.gating_network = sg\n",
    "\n",
    "# for param in t.model.gating_network.parameters():\n",
    "#     print(param.requires_grad)\n",
    "\n",
    "for param in t.model.gating_network.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# for param in t.model.gating_network.parameters():\n",
    "#     print(param.requires_grad)\n",
    "\n",
    "for param in t.model.experts.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optim = torch.optim.SGD(t.model.gating_network.parameters(), lr=args.lr)\n",
    "\n",
    "t.optimizer = optim"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using a simple convolutional gate\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# loads are off because here all non-zero weights are counted and I've changed the gating to be dense\n",
    "t.fit(train_loader, valid_loader, epochs=10, log=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/216 [00:00<?, ?batch/s]SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.003\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 1\n",
      "100%|██████████| 216/216 [00:02<00:00, 86.98batch/s, loss=0.657]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 49.73batch/s, loss=0.619]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.6377758334080378; accuracy: 0.8666666666666667\n",
      "\n",
      "Epoch 2\n",
      "100%|██████████| 216/216 [00:02<00:00, 86.02batch/s, loss=0.495] \n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 48.01batch/s, loss=0.468]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.474836823840936; accuracy: 0.902\n",
      "\n",
      "Epoch 3\n",
      "100%|██████████| 216/216 [00:02<00:00, 81.44batch/s, loss=0.398]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 52.01batch/s, loss=0.4]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.38307400544484455; accuracy: 0.9195\n",
      "\n",
      "Epoch 4\n",
      "100%|██████████| 216/216 [00:02<00:00, 88.93batch/s, loss=0.328] \n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 53.07batch/s, loss=0.368]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.3294263655940692; accuracy: 0.9281666666666667\n",
      "\n",
      "Epoch 5\n",
      "100%|██████████| 216/216 [00:02<00:00, 81.00batch/s, loss=0.332]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 53.36batch/s, loss=0.34]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.2901939731091261; accuracy: 0.9341666666666667\n",
      "\n",
      "Epoch 6\n",
      "100%|██████████| 216/216 [00:02<00:00, 85.66batch/s, loss=0.25] \n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 42.31batch/s, loss=0.269]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.2655865407238404; accuracy: 0.9381666666666667\n",
      "\n",
      "Epoch 7\n",
      "100%|██████████| 216/216 [00:02<00:00, 86.83batch/s, loss=0.193]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 53.32batch/s, loss=0.223]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.2406349858889977; accuracy: 0.9418333333333333\n",
      "\n",
      "Epoch 8\n",
      "100%|██████████| 216/216 [00:02<00:00, 85.41batch/s, loss=0.242]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 50.70batch/s, loss=0.175]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.2251062033077081; accuracy: 0.9481666666666667\n",
      "\n",
      "Epoch 9\n",
      "100%|██████████| 216/216 [00:02<00:00, 85.32batch/s, loss=0.158]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 50.22batch/s, loss=0.201]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]Validation loss: 0.21177562388281027; accuracy: 0.9496666666666667\n",
      "\n",
      "Epoch 10\n",
      "100%|██████████| 216/216 [00:02<00:00, 82.51batch/s, loss=0.135]\n",
      "  0%|          | 0/24 [00:00<?, ?batch/s]Loads for the epoch label 0: [5366. 5366. 5366. 5366. 5366.]\n",
      "Loads for the epoch label 1: [6046. 6046. 6046. 6046. 6046.]\n",
      "Loads for the epoch label 2: [5356. 5356. 5356. 5356. 5356.]\n",
      "Loads for the epoch label 3: [5495. 5495. 5495. 5495. 5495.]\n",
      "Loads for the epoch label 4: [5267. 5267. 5267. 5267. 5267.]\n",
      "Loads for the epoch label 5: [4875. 4875. 4875. 4875. 4875.]\n",
      "Loads for the epoch label 6: [5291. 5291. 5291. 5291. 5291.]\n",
      "Loads for the epoch label 7: [5641. 5641. 5641. 5641. 5641.]\n",
      "Loads for the epoch label 8: [5275. 5275. 5275. 5275. 5275.]\n",
      "Loads for the epoch label 9: [5388. 5388. 5388. 5388. 5388.]\n",
      "Loads for the epoch: [54000. 54000. 54000. 54000. 54000.]\n",
      "\n",
      "Validating\n",
      "100%|██████████| 24/24 [00:00<00:00, 52.39batch/s, loss=0.237]Validation loss: 0.2006617939720551; accuracy: 0.9526666666666667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "t.test(test_loader, metric_dict);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?batch/s]\n",
      "Testing\n",
      "100%|██████████| 40/40 [00:00<00:00, 68.87batch/s]Results: \n",
      "Accuracy: 0.9568\n",
      "NLL: 0.179173562861979\n",
      "ECE: 0.06775618422031403\n",
      "Brier: 0.07396664386615157\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The gating network being trained post-hoc but via primarily the ensemble loss is a very indirect approach to the MoE post-hoc gating training, reminiscent of the end-to-edn approach, only split apart to take turns. We might expect better results if we define a loss specifically for the gating network and train it in isolation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from methods.moe.laplace_gating import get_adjusted_loader\n",
    "\n",
    "t.model.to('cpu')\n",
    "\n",
    "gate_train_loader = get_adjusted_loader(t.model.experts, train_loader)\n",
    "gate_val_loader = get_adjusted_loader(t.model.experts, valid_loader)\n",
    "\n",
    "t.model.to(t.device);\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "sg = SimpleConvGate(28, 5)\n",
    "gate_train_epochs = 10\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using a simple convolutional gate\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# t.device='cpu'\n",
    "optim = torch.optim.Adam(sg.parameters(), weight_decay=0.001)\n",
    "\n",
    "sg.to(t.device)\n",
    "\n",
    "from tqdm import tqdm\n",
    "for i in range(gate_train_epochs):\n",
    "    \n",
    "    print(f'Epoch {i + 1}')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sg.train()\n",
    "\n",
    "    with tqdm(gate_train_loader, unit=\"batch\") as tepoch:\n",
    "        for X, y in tepoch:\n",
    "            X, y = X.to(t.device), y.to(t.device)\n",
    "            \n",
    "            # compute loss        \n",
    "            y_hat = sg(X)\n",
    "            loss = nn.functional.cross_entropy(y_hat, y)\n",
    "            \n",
    "            # backpropogate\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            loss = loss.item()\n",
    "            tepoch.set_postfix(loss=loss)\n",
    "            _, predicted = torch.max(y_hat, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += X.shape[0]\n",
    "\n",
    "    print(f'\\nAccuracy: {correct/total}')\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sg.train()\n",
    "    \n",
    "    with tqdm(gate_val_loader, unit=\"batch\") as tepoch:\n",
    "        for X, y in tepoch:\n",
    "            X, y = X.to(t.device), y.to(t.device)\n",
    "            \n",
    "            # compute loss        \n",
    "            y_hat = sg(X)\n",
    "            loss = nn.functional.cross_entropy(y_hat, y)\n",
    "\n",
    "            loss = loss.item()\n",
    "            tepoch.set_postfix(loss=loss)\n",
    "            _, predicted = torch.max(y_hat, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += X.shape[0]\n",
    "\n",
    "    print(f'\\nValidation accuracy: {correct/total}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|▏         | 3/216 [00:00<00:09, 21.76batch/s, loss=1.08]Epoch 1\n",
      "100%|██████████| 216/216 [00:06<00:00, 33.00batch/s, loss=0.123]\n",
      " 21%|██        | 5/24 [00:00<00:00, 42.06batch/s, loss=0.13] Accuracy: 0.9203518518518519\n",
      "100%|██████████| 24/24 [00:00<00:00, 39.56batch/s, loss=0.155]\n",
      "  1%|          | 2/216 [00:00<00:12, 17.56batch/s, loss=0.165]Validation accuracy: 0.9668333333333333\n",
      "Epoch 2\n",
      "100%|██████████| 216/216 [00:07<00:00, 30.74batch/s, loss=0.0855]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 39.52batch/s, loss=0.0778]Accuracy: 0.9757037037037037\n",
      "100%|██████████| 24/24 [00:00<00:00, 33.23batch/s, loss=0.091]\n",
      "  1%|▏         | 3/216 [00:00<00:08, 26.10batch/s, loss=0.0478]Validation accuracy: 0.9771666666666666\n",
      "Epoch 3\n",
      "100%|██████████| 216/216 [00:06<00:00, 31.12batch/s, loss=0.0557]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 33.91batch/s, loss=0.0837]Accuracy: 0.982925925925926\n",
      "100%|██████████| 24/24 [00:00<00:00, 38.68batch/s, loss=0.0449]\n",
      "  1%|          | 2/216 [00:00<00:12, 17.38batch/s, loss=0.0668]Validation accuracy: 0.9798333333333333\n",
      "Epoch 4\n",
      "100%|██████████| 216/216 [00:07<00:00, 30.53batch/s, loss=0.0459]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 33.20batch/s, loss=0.0537]Accuracy: 0.9866666666666667\n",
      "100%|██████████| 24/24 [00:00<00:00, 33.19batch/s, loss=0.0516]\n",
      "  1%|▏         | 3/216 [00:00<00:07, 26.79batch/s, loss=0.0392]Validation accuracy: 0.9815\n",
      "Epoch 5\n",
      "100%|██████████| 216/216 [00:06<00:00, 32.88batch/s, loss=0.0778]\n",
      " 21%|██        | 5/24 [00:00<00:00, 41.73batch/s, loss=0.0804]Accuracy: 0.9892777777777778\n",
      "100%|██████████| 24/24 [00:00<00:00, 38.90batch/s, loss=0.091]\n",
      "  1%|▏         | 3/216 [00:00<00:09, 22.87batch/s, loss=0.041] Validation accuracy: 0.9825\n",
      "Epoch 6\n",
      "100%|██████████| 216/216 [00:06<00:00, 31.21batch/s, loss=0.027]\n",
      " 21%|██        | 5/24 [00:00<00:00, 41.98batch/s, loss=0.0417]Accuracy: 0.9906111111111111\n",
      "100%|██████████| 24/24 [00:00<00:00, 33.30batch/s, loss=0.0696]\n",
      "  1%|          | 2/216 [00:00<00:11, 19.08batch/s, loss=0.0188]Validation accuracy: 0.9821666666666666\n",
      "Epoch 7\n",
      "100%|██████████| 216/216 [00:07<00:00, 29.97batch/s, loss=0.0219]\n",
      " 21%|██        | 5/24 [00:00<00:00, 42.15batch/s, loss=0.0726]Accuracy: 0.9918703703703704\n",
      "100%|██████████| 24/24 [00:00<00:00, 39.35batch/s, loss=0.0841]\n",
      "  1%|          | 2/216 [00:00<00:12, 17.51batch/s, loss=0.0309]Validation accuracy: 0.9838333333333333\n",
      "Epoch 8\n",
      "100%|██████████| 216/216 [00:06<00:00, 31.70batch/s, loss=0.0252]\n",
      " 21%|██        | 5/24 [00:00<00:00, 41.90batch/s, loss=0.0542]Accuracy: 0.993037037037037\n",
      "100%|██████████| 24/24 [00:00<00:00, 33.96batch/s, loss=0.042]\n",
      "  1%|          | 2/216 [00:00<00:11, 19.15batch/s, loss=0.0152]Validation accuracy: 0.9831666666666666\n",
      "Epoch 9\n",
      "100%|██████████| 216/216 [00:07<00:00, 29.57batch/s, loss=0.0288]\n",
      " 21%|██        | 5/24 [00:00<00:00, 41.96batch/s, loss=0.0457]Accuracy: 0.9940740740740741\n",
      "100%|██████████| 24/24 [00:00<00:00, 38.52batch/s, loss=0.0807]\n",
      "  1%|▏         | 3/216 [00:00<00:10, 20.92batch/s, loss=0.028] Validation accuracy: 0.9841666666666666\n",
      "Epoch 10\n",
      "100%|██████████| 216/216 [00:07<00:00, 30.84batch/s, loss=0.0279]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 34.68batch/s, loss=0.0755]Accuracy: 0.9942222222222222\n",
      "100%|██████████| 24/24 [00:00<00:00, 32.35batch/s, loss=0.0484]Validation accuracy: 0.9845\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\n",
    "t.model.gating_network = GateWrapper(sg).to(t.device)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "t.test(test_loader, metric_dict);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?batch/s]\n",
      "Testing\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 40/40 [00:00<00:00, 71.44batch/s]Results: \n",
      "Accuracy: 0.9821\n",
      "NLL: 0.06378110595978796\n",
      "ECE: 0.018323120385408398\n",
      "Brier: 0.02862546475371346\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we observe more of a problem: the training loss of the post-hoc trained gating network is nearly zero, and the accuracy over 95%, indicating only limited further training would be possible, however, the generalisation error, reflecting the overall MoE error in this case nearly perfectly, is still somewhat higher. Even with some level of weight regularisation introduced when training the gating network, the problem persists. We are pushing the generealisation error limits here, and it is likely the sheer \"learnability\" of the dataset is affecting this to some extent."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from methods.moe.gate_models import SimpleConvGate, GateWrapper\n",
    "from methods.moe.laplace_gating import get_adjusted_loader\n",
    "import gate_train as gt\n",
    "from importlib import reload"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from methods.moe.gate_models import get_gating_network"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gt = reload(gt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "t.model.to('cpu')\n",
    "\n",
    "gate_train_loader = get_adjusted_loader(t.model.experts, train_loader, return_original=True)\n",
    "gate_val_loader = get_adjusted_loader(t.model.experts, valid_loader, return_original=True)\n",
    "\n",
    "t.model.to(t.device);"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "(gate_train_loader.dataset.new_labels == 4).sum() / gate_train_loader.dataset.new_labels.shape[0] "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.1965)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# mnist 5 lenet MoE with convolutional gating\n",
    "run_id_moe_mnist_conv = 'run-20210713_152705-r9znwdrf'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# sg = GateWrapper(SimpleConvGate(28, 5))\n",
    "sg = get_gating_network(None, 'conv', 28*28, 5)\n",
    "sg.to('cuda')\n",
    "exps, g = gt.fit_gating(t.model.experts, sg, gate_train_loader, gate_val_loader, 0.001, 0, gt.loss_sum_criterion, 'cuda', 10)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 2/216 [00:00<00:11, 18.27batch/s, loss=8.37]Using a simple convolutional gate\n",
      "Epoch 1\n",
      "100%|██████████| 216/216 [00:08<00:00, 26.47batch/s, loss=0.768]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 25.79batch/s, loss=0.618]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9082407407407408\n",
      "Gate oracle accuracy 0.9062407407407408\n",
      "Loss 2.231543489076473\n",
      "100%|██████████| 24/24 [00:00<00:00, 26.54batch/s, loss=0.58]\n",
      "  1%|          | 2/216 [00:00<00:11, 18.81batch/s, loss=0.531]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9656666666666667\n",
      "Gate oracle accuracy 0.9691666666666666\n",
      "Loss 0.7032889698942503\n",
      "Epoch 2\n",
      "100%|██████████| 216/216 [00:08<00:00, 26.92batch/s, loss=0.467]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 32.48batch/s, loss=0.314]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9743703703703703\n",
      "Gate oracle accuracy 0.9758333333333333\n",
      "Loss 0.5031139244221978\n",
      "100%|██████████| 24/24 [00:00<00:00, 29.87batch/s, loss=0.333]\n",
      "  0%|          | 1/216 [00:00<00:37,  5.69batch/s, loss=0.32]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9763333333333334\n",
      "Gate oracle accuracy 0.9796666666666667\n",
      "Loss 0.39606405049562454\n",
      "Epoch 3\n",
      "100%|██████████| 216/216 [00:07<00:00, 27.94batch/s, loss=0.271]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 31.47batch/s, loss=0.256]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9814259259259259\n",
      "Gate oracle accuracy 0.9830740740740741\n",
      "Loss 0.32600736148931364\n",
      "100%|██████████| 24/24 [00:00<00:00, 24.70batch/s, loss=0.306]\n",
      "  0%|          | 1/216 [00:00<00:41,  5.19batch/s, loss=0.281]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9795\n",
      "Gate oracle accuracy 0.9836666666666667\n",
      "Loss 0.29792239516973495\n",
      "Epoch 4\n",
      "100%|██████████| 216/216 [00:08<00:00, 26.91batch/s, loss=0.206]\n",
      " 12%|█▎        | 3/24 [00:00<00:00, 28.97batch/s, loss=0.203]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9844074074074074\n",
      "Gate oracle accuracy 0.9861851851851852\n",
      "Loss 0.24922305404174108\n",
      "100%|██████████| 24/24 [00:00<00:00, 28.83batch/s, loss=0.261]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9823333333333333\n",
      "Gate oracle accuracy 0.987\n",
      "Loss 0.23393000041445097\n",
      "Epoch 5\n",
      "100%|██████████| 216/216 [00:07<00:00, 27.05batch/s, loss=0.267]\n",
      " 12%|█▎        | 3/24 [00:00<00:00, 24.84batch/s, loss=0.221]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9866296296296296\n",
      "Gate oracle accuracy 0.988574074074074\n",
      "Loss 0.20258254783779936\n",
      "100%|██████████| 24/24 [00:00<00:00, 26.66batch/s, loss=0.131]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.984\n",
      "Gate oracle accuracy 0.9886666666666667\n",
      "Loss 0.20418504811823368\n",
      "Epoch 6\n",
      "100%|██████████| 216/216 [00:07<00:00, 27.51batch/s, loss=0.0848]\n",
      " 12%|█▎        | 3/24 [00:00<00:00, 27.65batch/s, loss=0.234]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9887222222222222\n",
      "Gate oracle accuracy 0.9903888888888889\n",
      "Loss 0.17163785651360672\n",
      "100%|██████████| 24/24 [00:00<00:00, 30.55batch/s, loss=0.272]\n",
      "  0%|          | 1/216 [00:00<00:41,  5.18batch/s, loss=0.188]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9835\n",
      "Gate oracle accuracy 0.9885\n",
      "Loss 0.1890912481273214\n",
      "Epoch 7\n",
      "100%|██████████| 216/216 [00:07<00:00, 28.15batch/s, loss=0.275]\n",
      " 12%|█▎        | 3/24 [00:00<00:00, 28.67batch/s, loss=0.213]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9896296296296296\n",
      "Gate oracle accuracy 0.9915\n",
      "Loss 0.15135628773175455\n",
      "100%|██████████| 24/24 [00:00<00:00, 29.84batch/s, loss=0.0988]\n",
      "  0%|          | 0/216 [00:00<?, ?batch/s]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9848333333333333\n",
      "Gate oracle accuracy 0.9896666666666667\n",
      "Loss 0.1658578865850965\n",
      "Epoch 8\n",
      "100%|██████████| 216/216 [00:07<00:00, 27.96batch/s, loss=0.101]\n",
      " 17%|█▋        | 4/24 [00:00<00:00, 31.41batch/s, loss=0.191]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.990574074074074\n",
      "Gate oracle accuracy 0.9925555555555555\n",
      "Loss 0.1370366619537688\n",
      "100%|██████████| 24/24 [00:00<00:00, 29.85batch/s, loss=0.104]\n",
      "  0%|          | 1/216 [00:00<00:41,  5.23batch/s, loss=0.0945]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9871666666666666\n",
      "Gate oracle accuracy 0.9918333333333333\n",
      "Loss 0.14094210028027496\n",
      "Epoch 9\n",
      "100%|██████████| 216/216 [00:07<00:00, 27.94batch/s, loss=0.134]\n",
      " 12%|█▎        | 3/24 [00:00<00:00, 27.93batch/s, loss=0.146]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9911666666666666\n",
      "Gate oracle accuracy 0.9931851851851852\n",
      "Loss 0.1203290853795975\n",
      "100%|██████████| 24/24 [00:00<00:00, 30.35batch/s, loss=0.142]\n",
      "  0%|          | 1/216 [00:00<00:40,  5.28batch/s, loss=0.0424]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9865\n",
      "Gate oracle accuracy 0.9911666666666666\n",
      "Loss 0.14572914751867452\n",
      "Epoch 10\n",
      "100%|██████████| 216/216 [00:07<00:00, 27.41batch/s, loss=0.154]\n",
      "  8%|▊         | 2/24 [00:00<00:01, 16.70batch/s, loss=0.184]\n",
      "Training\n",
      "--------------\n",
      "Ensemble accuracy 0.9918888888888889\n",
      "Gate oracle accuracy 0.9938888888888889\n",
      "Loss 0.10653732442814443\n",
      "100%|██████████| 24/24 [00:01<00:00, 21.06batch/s, loss=0.0892]\n",
      "Validation\n",
      "--------------\n",
      "Ensemble accuracy 0.9878333333333333\n",
      "Gate oracle accuracy 0.9926666666666667\n",
      "Loss 0.12807258878213665\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "dummy_args = Configuration(DEFAULT_DICT)\n",
    "dummy_args.moe_gating = 'simple'\n",
    "dummy_args.method = 'moe'\n",
    "dummy_args.n = 5\n",
    "dummy_args.model = 'lenet'\n",
    "dummy_args.optimizer = 'adam'\n",
    "# args.cpu = True\n",
    "dummy_args.moe_type = 'dense'\n",
    "dummy_args.predict_gated = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "dummy_trainer = get_trainer(dummy_args, 'cuda')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using a simple gate\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "dummy_trainer.model.gating_network = g\n",
    "dummy_trainer.model.experts = exps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "dummy_trainer.test(test_loader, metric_dict);"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?batch/s]\n",
      "Testing\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/homes/gp491/deepens/proj-env/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 40/40 [00:00<00:00, 63.39batch/s]Results: \n",
      "Accuracy: 0.9833\n",
      "NLL: 0.08413592033321038\n",
      "ECE: 0.015074500668048853\n",
      "Brier: 0.028405361668774276\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}